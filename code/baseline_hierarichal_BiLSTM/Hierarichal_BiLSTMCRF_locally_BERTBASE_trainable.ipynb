{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Iip3RtlSNswV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iip3RtlSNswV",
        "outputId": "a239af36-6346-4703-e082-2f7eb1e378b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting allennlp\n",
            "  Downloading allennlp-2.10.1-py3-none-any.whl (730 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.2/730.2 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch<1.13.0,>=1.10.0 (from allennlp)\n",
            "  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision<0.14.0,>=0.8.1 (from allennlp)\n",
            "  Downloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cached-path<1.2.0,>=1.1.3 (from allennlp)\n",
            "  Downloading cached_path-1.1.6-py3-none-any.whl (26 kB)\n",
            "Collecting fairscale==0.4.6 (from allennlp)\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.8.1)\n",
            "Collecting spacy<3.4,>=2.1.0 (from allennlp)\n",
            "  Downloading spacy-3.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.4 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.22.4)\n",
            "Collecting tensorboardX>=1.2 (from allennlp)\n",
            "  Downloading tensorboardX-2.6.1-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.28 (from allennlp)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.10/dist-packages (from allennlp) (4.65.0)\n",
            "Requirement already satisfied: h5py>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.10.1)\n",
            "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.10/dist-packages (from allennlp) (7.2.2)\n",
            "Collecting transformers<4.21,>=4.1 (from allennlp)\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece>=0.1.96 (from allennlp)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock<3.8,>=3.3 (from allennlp)\n",
            "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
            "Collecting lmdb>=1.2.1 (from allennlp)\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools>=8.12.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (9.1.0)\n",
            "Collecting termcolor==1.1.0 (from allennlp)\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb<0.13.0,>=0.10.0 (from allennlp)\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.16 (from allennlp)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill>=0.3.4 (from allennlp)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting base58>=2.1.1 (from allennlp)\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting sacremoses (from allennlp)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.7.0)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.20.3)\n",
            "Requirement already satisfied: traitlets>5.1.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (5.7.1)\n",
            "Collecting jsonnet>=0.10.0 (from allennlp)\n",
            "  Downloading jsonnet-0.20.0.tar.gz (594 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.2/594.2 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rich<13.0,>=12.1 (from cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2.0,>=1.0 (from cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading boto3-1.27.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.9/135.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-storage<3.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (2.8.0)\n",
            "Collecting huggingface-hub>=0.0.16 (from allennlp)\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.6.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (23.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (2023.5.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.1->allennlp) (3.1.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.8)\n",
            "Collecting thinc<8.1.0,>=8.0.14 (from spacy<3.4,>=2.1.0->allennlp)\n",
            "  Downloading thinc-8.0.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (659 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.5/659.5 kB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.7.9)\n",
            "Collecting wasabi<1.1.0,>=0.9.1 (from spacy<3.4,>=2.1.0->allennlp)\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.8)\n",
            "Collecting typer>=0.4.1 (from allennlp)\n",
            "  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (6.3.0)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 (from spacy<3.4,>=2.1.0->allennlp)\n",
            "  Downloading pydantic-1.8.2-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (67.7.2)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.0.16->allennlp)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.3.0)\n",
            "INFO: pip is looking at multiple versions of tensorboardx to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorboardX>=1.2 (from allennlp)\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision<0.14.0,>=0.8.1->allennlp) (8.4.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers<4.21,>=4.1->allennlp)\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython>=1.0.0 (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n",
            "Collecting shortuuid>=0.5.0 (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading sentry_sdk-1.26.0-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.16.0)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting botocore<1.31.0,>=1.30.0 (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading botocore-1.30.0-py3-none-any.whl (11.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.17.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.11.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.3.2)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.5.0)\n",
            "Collecting commonmark<0.10.0,>=0.9.0 (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (2.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.4,>=2.1.0->allennlp) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.31.0,>=1.30.0->boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.8.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.59.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.5.0)\n",
            "Building wheels for collected packages: fairscale, termcolor, jsonnet, sacremoses, pathtools\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307224 sha256=8ad3e654bcfd4336e4863ffa0e1dbb3d8e752c6450f9e62dcbf78485e1417850\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/58/3d/e114952ab4a8f31eb9dae230658450afff986b211a5b1f2256\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=9d2d517b07f075f8a5f51a08bd39fbb869a56945c72f10f7bbf1525d64c4cf1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/49/46/1b13a65d8da11238af9616b00fdde6d45b0f95d9291bac8452\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.20.0-cp310-cp310-linux_x86_64.whl size=6620063 sha256=99d62ad3eba94293482fb3606f5a259c8e8d01b43352ff4e20b278193e98f0cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/0d/6b/5467dd1db9332ba4bd5cf4153e2870c5f89bb4db473d989cc2\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=1f749d4c3bcea7f67d0df1096ebd98e819cbc6da56175cf3744795fdb6f441e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=70c8a3be0a62edce61dca25ce4d3eb507a4b344d1af42bc627fbfacf509af246\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built fairscale termcolor jsonnet sacremoses pathtools\n",
            "Installing collected packages: wasabi, tokenizers, termcolor, sentencepiece, pathtools, lmdb, jsonnet, commonmark, typing-extensions, typer, tensorboardX, smmap, shortuuid, setproctitle, sentry-sdk, sacremoses, rich, requests, jmespath, filelock, docker-pycreds, dill, base58, torch, pydantic, huggingface-hub, gitdb, botocore, transformers, torchvision, thinc, s3transfer, GitPython, fairscale, wandb, spacy, boto3, cached-path, allennlp\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.2\n",
            "    Uninstalling wasabi-1.1.2:\n",
            "      Successfully uninstalled wasabi-1.1.2\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.3.0\n",
            "    Uninstalling termcolor-2.3.0:\n",
            "      Successfully uninstalled termcolor-2.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.6.3\n",
            "    Uninstalling typing_extensions-4.6.3:\n",
            "      Successfully uninstalled typing_extensions-4.6.3\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.7.0\n",
            "    Uninstalling typer-0.7.0:\n",
            "      Successfully uninstalled typer-0.7.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.4.2\n",
            "    Uninstalling rich-13.4.2:\n",
            "      Successfully uninstalled rich-13.4.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.12.2\n",
            "    Uninstalling filelock-3.12.2:\n",
            "      Successfully uninstalled filelock-3.12.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.9\n",
            "    Uninstalling pydantic-1.10.9:\n",
            "      Successfully uninstalled pydantic-1.10.9\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.10\n",
            "    Uninstalling thinc-8.1.10:\n",
            "      Successfully uninstalled thinc-8.1.10\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.5.3\n",
            "    Uninstalling spacy-3.5.3:\n",
            "      Successfully uninstalled spacy-3.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\n",
            "inflect 6.0.4 requires pydantic>=1.9.1, but you have pydantic 1.8.2 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.31 allennlp-2.10.1 base58-2.1.1 boto3-1.27.0 botocore-1.30.0 cached-path-1.1.6 commonmark-0.9.1 dill-0.3.6 docker-pycreds-0.4.0 fairscale-0.4.6 filelock-3.7.1 gitdb-4.0.10 huggingface-hub-0.10.1 jmespath-1.0.1 jsonnet-0.20.0 lmdb-1.4.1 pathtools-0.1.2 pydantic-1.8.2 requests-2.31.0 rich-12.6.0 s3transfer-0.6.1 sacremoses-0.0.53 sentencepiece-0.1.99 sentry-sdk-1.26.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 spacy-3.3.3 tensorboardX-2.6 termcolor-1.1.0 thinc-8.0.17 tokenizers-0.12.1 torch-1.12.1 torchvision-0.13.1 transformers-4.20.1 typer-0.4.2 typing-extensions-4.5.0 wandb-0.12.21 wasabi-0.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install allennlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e3XK41pBFxCv",
      "metadata": {
        "id": "e3XK41pBFxCv"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2a756f4a",
      "metadata": {
        "id": "2a756f4a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from sklearn.metrics import f1_score\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "60469712",
      "metadata": {
        "id": "60469712"
      },
      "outputs": [],
      "source": [
        "# Load the config file\n",
        "def load_config(config_path):\n",
        "    # Load and parse the config file\n",
        "    with open(config_path, 'r') as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    return config\n",
        "\n",
        "config = load_config('./HBiLSTM_CL.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c2522271",
      "metadata": {
        "id": "c2522271"
      },
      "outputs": [],
      "source": [
        "from data import SequenceClassificationDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "40bba0b3",
      "metadata": {
        "id": "40bba0b3"
      },
      "outputs": [],
      "source": [
        "root = '/content/'\n",
        "cl_train_dataset = SequenceClassificationDataset(Path(root, 'train_scibert.json'))\n",
        "cl_dev_dataset = SequenceClassificationDataset(Path(root, 'dev_scibert.json'))\n",
        "cl_test_dataset = SequenceClassificationDataset(Path(root, 'test_scibert.json'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "da5a847a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da5a847a",
        "outputId": "f9b41b76-a8c6-4251-c6a2-576da20fc228"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(cl_train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6348ec30",
      "metadata": {
        "id": "6348ec30"
      },
      "outputs": [],
      "source": [
        "batch_size=1\n",
        "train_dataloader = DataLoader(cl_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = DataLoader(cl_dev_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(cl_test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "  print(len(batch))\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWVINwvnGgom",
        "outputId": "4c471d48-8633-44b8-f989-29c94715b0b5"
      },
      "id": "MWVINwvnGgom",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OoK_tEeGgtu",
        "outputId": "856013fe-f14e-4e42-da5b-3f959ea32741"
      },
      "id": "6OoK_tEeGgtu",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'label_ids', 'attention_mask', 'sentence_masks'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch['input_ids'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "XgXRVUqiGu67",
        "outputId": "3b0455fa-4bef-4870-9584-213d22216cdd"
      },
      "id": "XgXRVUqiGu67",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7715b4485c33>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o5qUc-RZGu9T"
      },
      "id": "o5qUc-RZGu9T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b5uDc7ujGu_V"
      },
      "id": "b5uDc7ujGu_V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "a3119f7e",
      "metadata": {
        "id": "a3119f7e"
      },
      "outputs": [],
      "source": [
        "from models import BertHSLN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "SbDyRT2XPb7F",
      "metadata": {
        "id": "SbDyRT2XPb7F"
      },
      "outputs": [],
      "source": [
        "BERT_MODEL = \"bert-base-uncased\"\n",
        "mconfig = {\n",
        "    \"bert_model\": BERT_MODEL,\n",
        "    \"bert_trainable\": False,\n",
        "    \"model\": BertHSLN.__name__,\n",
        "    \"cacheable_tasks\": [],\n",
        "\n",
        "    \"dropout\": 0.5,\n",
        "    \"word_lstm_hs\": 384,\n",
        "    \"att_pooling_dim_ctx\": 100,\n",
        "    \"att_pooling_num_ctx\": 7,\n",
        "\n",
        "    \"lr\": 3e-05,\n",
        "    \"lr_epoch_decay\": 0.9,\n",
        "    \"batch_size\":  32,\n",
        "    \"max_seq_length\": 120,\n",
        "    \"max_epochs\": 20,\n",
        "    \"early_stopping\": 20,\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTEms-tMhBEb",
        "outputId": "9e339c80-59cc-4c5c-f05e-3bed60199413"
      },
      "id": "fTEms-tMhBEb",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "e1eae0a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1eae0a5",
        "outputId": "06495e5b-cf2e-4538-8e06-935ae797b30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device used: cuda\n"
          ]
        }
      ],
      "source": [
        "# assign device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"device used: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "2aKTXeEnR7wL",
      "metadata": {
        "id": "2aKTXeEnR7wL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3545c203-b061-41f8-bcc4-4fad31394b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention pooling dim: 5376\n"
          ]
        }
      ],
      "source": [
        "model = BertHSLN(mconfig, num_labels = 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "8381742c",
      "metadata": {
        "id": "8381742c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c59b760-9fb0-4283-d8fc-efc77f25ba95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "lr = mconfig['lr']#config['training']['learning_rate']\n",
        "'''max_grad_norm = config['training']['max_grad_norm']\n",
        "epochs = config['training']['epochs']\n",
        "\n",
        "num_total_steps = len(train_dataloader)*epochs\n",
        "num_warmup_steps = config['training']['num_warmup_steps']\n",
        "warmup_proportion = float(num_warmup_steps) / float(num_total_steps)  # 0.1\n",
        "'''\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=True)\n",
        "#epoch_scheduler = StepLR(optimizer, step_size=1, gamma=config['training'][\"lr_epoch_decay\"])\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps, num_training_steps = num_total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.optim import Adam\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        "epoch_scheduler = StepLR(optimizer, step_size=1, gamma=mconfig[\"lr_epoch_decay\"])\n"
      ],
      "metadata": {
        "id": "5r0No4MVdaMf"
      },
      "id": "5r0No4MVdaMf",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "6e9f688a",
      "metadata": {
        "id": "6e9f688a"
      },
      "outputs": [],
      "source": [
        "seed_val = config['training']['seed']\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "a5005f1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5005f1b",
        "outputId": "63f1c5b5-9e2c-4588-8ed9-01706eb208c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device used: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertHSLN(\n",
              "  (bert): BertTokenEmbedder(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (word_lstm): PytorchSeq2SeqWrapper(\n",
              "    (_module): LSTM(768, 384, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (attention_pooling): AttentionPooling(\n",
              "    (linear1): Linear(in_features=768, out_features=100, bias=True)\n",
              "    (linear2): Linear(in_features=100, out_features=7, bias=False)\n",
              "  )\n",
              "  (sentence_lstm): PytorchSeq2SeqWrapper(\n",
              "    (_module): LSTM(5376, 384, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (crf): CRFOutputLayer(\n",
              "    (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              "    (crf): ConditionalRandomField()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "# assign device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"device used: {device}\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "864b9de3",
      "metadata": {
        "id": "864b9de3"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import operator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "PudgU89SdvYZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PudgU89SdvYZ",
        "outputId": "9183717f-cdf5-4436-f3b7-67c086e939e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21328998"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from allennlp.common.util import pad_sequence_to_length\n",
        "\n",
        "def batch_to_tensor(b):\n",
        "    # convert to dictionary of tensors and pad the tensors\n",
        "    max_sentence_len = 128\n",
        "    result = {}\n",
        "    for k, v in b.items():\n",
        "\n",
        "        if k in [\"input_ids\", \"attention_mask\"]:\n",
        "            # determine the max sentence len in the batch\n",
        "            max_sentence_len = -1\n",
        "            for sentence in v:\n",
        "                sentence = torch.cat(sentence)\n",
        "                max_sentence_len = max(len(sentence), max_sentence_len)\n",
        "            # pad the sentences to max sentence len\n",
        "            for i, sentence in enumerate(v):\n",
        "                v[i] = pad_sequence_to_length(sentence, desired_length=max_sentence_len)\n",
        "        if k!='doc_name' and k!= 'label_ids':\n",
        "            result[k] = torch.tensor(v).unsqueeze(0)\n",
        "        elif k == 'label_ids':\n",
        "            result[k] = torch.tensor(v)\n",
        "        else:\n",
        "            result[k] = v\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "-58DiXbQg4Hg"
      },
      "id": "-58DiXbQg4Hg",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "0fef0f63",
      "metadata": {
        "id": "0fef0f63"
      },
      "outputs": [],
      "source": [
        "def training_step(model, criterion, optimizer, scheduler, data_loader):\n",
        "    model.train()  # Set the model to train mode\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_predicted = []\n",
        "\n",
        "    for batch in data_loader:\n",
        "        batch = batch_to_tensor(batch)\n",
        "        for key, tensor in batch.items():\n",
        "            batch[key] = tensor.to(device)\n",
        "        labels = batch['label_ids']\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(batch, labels)\n",
        "\n",
        "\n",
        "        #max_sequence_length = output.size(1)\n",
        "        #tlengths = torch.tensor(lengths).unsqueeze(1)\n",
        "        #mask = torch.arange(max_sequence_length).unsqueeze(0).to(device) < tlengths\n",
        "        #masked_output = output['predicted_label']\n",
        "\n",
        "        # Calculate loss\n",
        "        #loss = criterion(masked_output, labels)\n",
        "        loss = output['loss']\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        #predicted_labels = masked_output.argmax(dim=-1)\n",
        "        #correct = (predicted_labels == labels).sum().item()\n",
        "        #train_correct += correct\n",
        "        #train_total += labels.shape[0]\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # save all epoch labels and predicted labels\n",
        "        #all_labels.extend(labels.cpu())\n",
        "        #all_predicted.extend(predicted_labels.cpu())\n",
        "    epoch_scheduler.step()\n",
        "    # Calculate epoch statistics\n",
        "    train_loss /= len(data_loader)\n",
        "    #train_accuracy = train_correct / train_total\n",
        "    # calculate f1\n",
        "    #f1 = f1_score(all_labels, all_predicted, average='weighted')\n",
        "    return train_loss#, train_accuracy, f1\n",
        "\n",
        "\n",
        "def validation_step(model, criterion, data_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    dev_loss = 0.0\n",
        "    dev_correct = 0\n",
        "    dev_total = 0\n",
        "    all_labels = []\n",
        "    all_predicted = []\n",
        "\n",
        "\n",
        "    for batch in data_loader:\n",
        "        with torch.no_grad():\n",
        "            batch = batch_to_tensor(batch)\n",
        "            for key, tensor in batch.items():\n",
        "               batch[key] = tensor.to(device)\n",
        "            labels = batch['label_ids']\n",
        "            # Forward pass\n",
        "            outputs = model(batch)\n",
        "            #max_sequence_length = outputs.size(1)\n",
        "            #tlengths = torch.tensor(lengths).unsqueeze(1)\n",
        "            #mask = torch.arange(max_sequence_length).unsqueeze(0).to(device) < tlengths\n",
        "            #masked_output = output['predicted_label']\n",
        "\n",
        "            # Calculate loss\n",
        "            #loss = criterion(masked_output, labels)\n",
        "            predicted_label = outputs['predicted_label']\n",
        "            #dev_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            #predicted_labels = masked_output.argmax(dim=-1)\n",
        "            #correct = (predicted_labels == labels).sum().item()\n",
        "            #dev_correct += correct\n",
        "            #dev_total += labels.shape[0]\n",
        "\n",
        "            # save all epoch labels and predicted labels\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predicted.extend(predicted_label.cpu().numpy())\n",
        "\n",
        "    # Calculate epoch statistics\n",
        "    #dev_loss /= len(data_loader)\n",
        "    #dev_accuracy = dev_correct / dev_total\n",
        "    # calculate f1\n",
        "    all_predicted = functools.reduce(operator.iconcat, all_predicted, [])\n",
        "    all_labels = functools.reduce(operator.iconcat, all_labels, [])\n",
        "    print(len(all_predicted), len(all_labels))\n",
        "    f1 = f1_score(all_labels, all_predicted, average='weighted')\n",
        "    return f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "21f98b2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "21f98b2a",
        "outputId": "3702392e-5b66-4075-bcec-b4095dd0a905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Epoch 1 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300 - Training Loss: 563.1874\n",
            "1394 1394\n",
            "Epoch 1/300 - F1 0.10956163280252004\n",
            "======== Epoch 2 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/300 - Training Loss: 526.7592\n",
            "1394 1394\n",
            "Epoch 2/300 - F1 0.11063654436120131\n",
            "======== Epoch 3 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/300 - Training Loss: 511.9383\n",
            "1394 1394\n",
            "Epoch 3/300 - F1 0.15662307402021475\n",
            "======== Epoch 4 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/300 - Training Loss: 484.5358\n",
            "1394 1394\n",
            "Epoch 4/300 - F1 0.1869356858246673\n",
            "======== Epoch 5 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/300 - Training Loss: 465.3927\n",
            "1394 1394\n",
            "Epoch 5/300 - F1 0.31807713936954973\n",
            "======== Epoch 6 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/300 - Training Loss: 458.5605\n",
            "1394 1394\n",
            "Epoch 6/300 - F1 0.38951293019976124\n",
            "======== Epoch 7 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/300 - Training Loss: 444.6204\n",
            "1394 1394\n",
            "Epoch 7/300 - F1 0.33366829614635896\n",
            "======== Epoch 8 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/300 - Training Loss: 440.9730\n",
            "1394 1394\n",
            "Epoch 8/300 - F1 0.36585451637265604\n",
            "======== Epoch 9 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/300 - Training Loss: 427.3885\n",
            "1394 1394\n",
            "Epoch 9/300 - F1 0.4125277350524367\n",
            "======== Epoch 10 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/300 - Training Loss: 424.5659\n",
            "1394 1394\n",
            "Epoch 10/300 - F1 0.3602111970443652\n",
            "======== Epoch 11 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/300 - Training Loss: 421.7942\n",
            "1394 1394\n",
            "Epoch 11/300 - F1 0.4235958319186464\n",
            "======== Epoch 12 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/300 - Training Loss: 411.1661\n",
            "1394 1394\n",
            "Epoch 12/300 - F1 0.3955682677498254\n",
            "======== Epoch 13 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/300 - Training Loss: 404.9735\n",
            "1394 1394\n",
            "Epoch 13/300 - F1 0.39619595544865643\n",
            "======== Epoch 14 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/300 - Training Loss: 395.3669\n",
            "1394 1394\n",
            "Epoch 14/300 - F1 0.41982814284658904\n",
            "======== Epoch 15 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/300 - Training Loss: 395.0020\n",
            "1394 1394\n",
            "Epoch 15/300 - F1 0.41522763838777543\n",
            "======== Epoch 16 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/300 - Training Loss: 392.1894\n",
            "1394 1394\n",
            "Epoch 16/300 - F1 0.42569990609184616\n",
            "======== Epoch 17 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/300 - Training Loss: 383.3941\n",
            "1394 1394\n",
            "Epoch 17/300 - F1 0.43267259475598113\n",
            "======== Epoch 18 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/300 - Training Loss: 380.1653\n",
            "1394 1394\n",
            "Epoch 18/300 - F1 0.4366404721801315\n",
            "======== Epoch 19 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/300 - Training Loss: 375.0520\n",
            "1394 1394\n",
            "Epoch 19/300 - F1 0.4115739403731627\n",
            "======== Epoch 20 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/300 - Training Loss: 372.8495\n",
            "1394 1394\n",
            "Epoch 20/300 - F1 0.43048099662055306\n",
            "======== Epoch 21 / 300 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-05cb46068864>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtrain_epoch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#train_epoch_acc.append(train_accuracy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-d25d698c5d0b>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(model, criterion, optimizer, scheduler, data_loader)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_epoch_losses = []\n",
        "train_epoch_acc = []\n",
        "train_epoch_f1 = []\n",
        "\n",
        "dev_epoch_losses = []\n",
        "dev_epoch_acc = []\n",
        "dev_epoch_f1 = []\n",
        "\n",
        "\n",
        "best_dev_f1 = 0\n",
        "best_model = None\n",
        "\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
        "\n",
        "    # Training\n",
        "    train_loss = training_step(model, criterion, optimizer, scheduler, train_dataloader)\n",
        "    train_epoch_losses.append(train_loss)\n",
        "    #train_epoch_acc.append(train_accuracy)\n",
        "    #train_epoch_f1.append(train_f1)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    dev_f1 = validation_step(model, criterion, valid_dataloader)\n",
        "    #dev_epoch_losses.append(dev_loss)\n",
        "    #dev_epoch_acc.append(dev_accuracy)\n",
        "    dev_epoch_f1.append(dev_f1)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - F1 {dev_f1}\")\n",
        "\n",
        "    if dev_f1 > best_dev_f1:\n",
        "        best_dev_f1 = dev_f1\n",
        "        best_model = copy.deepcopy(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "11038361",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "11038361",
        "outputId": "6528fde1-1535-4840-a39d-dec1398b24b6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the epoch loss\n",
        "plt.plot(train_epoch_losses, label='Training Loss')\n",
        "#plt.plot(dev_epoch_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Epoch Loss')\n",
        "plt.show()\n",
        "\n",
        "# Plot the epoch accuracies\n",
        "#plt.plot(train_epoch_acc, label='Training acc')\n",
        "plt.plot(dev_epoch_f1, label='Validation acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Epoch Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Joffk4CRnlfM",
        "outputId": "6ecc66c2-713e-4c25-efc6-2cbc3f9f7d1e"
      },
      "id": "Joffk4CRnlfM",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "95e37c02",
      "metadata": {
        "id": "95e37c02"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def testing_step(model, data_loader, criterion):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for batch in data_loader:\n",
        "        with torch.no_grad():\n",
        "\n",
        "            batch = batch_to_tensor(batch)\n",
        "            for key, tensor in batch.items():\n",
        "               batch[key] = tensor.to(device)\n",
        "            labels = batch['label_ids']\n",
        "            # Forward pass\n",
        "            outputs = model(batch)\n",
        "            #max_sequence_length = outputs.size(1)\n",
        "            #tlengths = torch.tensor(lengths).unsqueeze(1)\n",
        "            #mask = torch.arange(max_sequence_length).unsqueeze(0).to(device) < tlengths\n",
        "            #masked_output = outputs[mask]\n",
        "            predicted_labels = outputs['predicted_label']\n",
        "\n",
        "            # Calculate loss\n",
        "            #loss = criterion(masked_output, labels)\n",
        "            #test_loss += loss.item()\n",
        "\n",
        "            # Store predictions and true labels\n",
        "            #predicted_labels = masked_output.argmax(dim=-1)\n",
        "            predictions.extend(predicted_labels.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Calculate accuracy\n",
        "            predicted_labels.detach().cpu().numpy()\n",
        "            labels = labels.to('cpu')\n",
        "\n",
        "            correct = (predicted_labels == labels).sum().item()\n",
        "            test_correct += correct\n",
        "            test_total += labels.shape[0]\n",
        "\n",
        "    predictions = functools.reduce(operator.iconcat, predictions, [])\n",
        "    true_labels = functools.reduce(operator.iconcat, true_labels, [])\n",
        "\n",
        "    test_loss /= len(data_loader)\n",
        "    test_accuracy = test_correct / test_total\n",
        "\n",
        "    print(f\"Testing Loss: {test_loss:.4f} - Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    print(classification_report(true_labels, predictions))\n",
        "    return test_loss, test_accuracy, predictions, true_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "aec7d93d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aec7d93d",
        "outputId": "ee48e44e-6cb5-45cb-d50c-9003bb30c2fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1 -1\n",
            "-1 -1\n",
            "-1 -1\n",
            "-1 -1\n",
            "-1 -1\n",
            "Testing Loss: 0.0000 - Testing Accuracy: 170.8000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.62      0.62       326\n",
            "           1       0.90      0.72      0.80       201\n",
            "           2       0.67      0.28      0.40       256\n",
            "           3       0.55      0.85      0.67       434\n",
            "           4       0.00      0.00      0.00        23\n",
            "           5       0.71      0.42      0.53        12\n",
            "           6       0.84      0.71      0.77        86\n",
            "\n",
            "    accuracy                           0.64      1338\n",
            "   macro avg       0.61      0.51      0.54      1338\n",
            "weighted avg       0.66      0.64      0.62      1338\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Testing loop\n",
        "test_loss, test_accuracy, predictions, true_labels = testing_step(model, test_dataloader, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "4f13e334",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f13e334",
        "outputId": "835ccb34-6860-4172-a3cf-ad053ebe268a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-29c5818d2fa6>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  result[k] = torch.tensor(v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1 -1\n",
            "-1 -1\n",
            "-1 -1\n",
            "-1 -1\n",
            "-1 -1\n",
            "Testing Loss: 0.0000 - Testing Accuracy: 169.8000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.63      0.62       326\n",
            "           1       0.80      0.72      0.76       201\n",
            "           2       0.72      0.29      0.42       256\n",
            "           3       0.57      0.83      0.67       434\n",
            "           4       0.00      0.00      0.00        23\n",
            "           5       0.71      0.42      0.53        12\n",
            "           6       0.87      0.67      0.76        86\n",
            "\n",
            "    accuracy                           0.63      1338\n",
            "   macro avg       0.61      0.51      0.54      1338\n",
            "weighted avg       0.65      0.63      0.62      1338\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Testing loop\n",
        "test_loss, test_accuracy, predictions, true_labels = testing_step(best_model, test_dataloader, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cdad956",
      "metadata": {
        "id": "5cdad956"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Lnlp",
      "language": "python",
      "name": "lnlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}