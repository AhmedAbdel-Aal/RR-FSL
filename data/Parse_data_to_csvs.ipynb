{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "797e51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b8666e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## path for the training and testing files\n",
    "main_path = '/Users/ahmed/Desktop/SS23/practical-legalNLP/data'\n",
    "\n",
    "path_cl_train = Path(main_path, 'CL','CL_train.json')\n",
    "path_cl_dev = Path(main_path, 'CL','CL_dev.json')\n",
    "path_cl_test = Path(main_path, 'CL','CL_test.json')\n",
    "\n",
    "path_it_train = Path(main_path, 'IT','IT_train.json')\n",
    "path_it_dev = Path(main_path, 'IT','IT_dev.json')\n",
    "path_it_test = Path(main_path, 'IT','IT_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd4cac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapper = {\n",
    "    \"Fact\": \"Fact\",\n",
    "    \"Issue\": \"Fact\",\n",
    "    \"ArgumentPetitioner\": \"Argument\",\n",
    "    \"ArgumentRespondent\": \"Argument\",\n",
    "    \"PrecedentReliedUpon\": \"Precedent\",\n",
    "    \"PrecedentNotReliedUpon\": \"Precedent\",\n",
    "    \"PrecedentOverruled\": \"Precedent\",\n",
    "    \"RatioOfTheDecision\": \"Ratio\",\n",
    "    \"RulingByLowerCourt\": \"RulingL\",\n",
    "    \"RulingByPresentCourt\": \"RulingP\",\n",
    "    \"Statute\": \"Statute\",\n",
    "    \"Dissent\": \"Dissent\",\n",
    "    \"None\": \"None\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae569e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(path) -> dict:\n",
    "    with open(path,'r') as f:\n",
    "        d = json.load(f)\n",
    "    return d\n",
    "\n",
    "def construct_data_labels(d: dict) -> dict:\n",
    "    data = {}\n",
    "    num_none_labels = 0\n",
    "    for i,file in enumerate(d.keys()):\n",
    "        #extract sentences and parse to list\n",
    "        sentences = d[file]['sentences']\n",
    "        if isinstance(sentences, str):\n",
    "            sentences = sentences[2:-2].split('\\', \\'')\n",
    "        \n",
    "        # extract labels and map to short labels\n",
    "        labels = d[file]['complete']\n",
    "        labels = [label_mapper[label] for label in labels]\n",
    "        \n",
    "        # remove sentences with None labels\n",
    "        new_sentences = []\n",
    "        new_labels = []\n",
    "        for j,l in enumerate(labels):\n",
    "            if (l == 'None'):\n",
    "                continue\n",
    "            else:\n",
    "                new_sentences.append(sentences[j])\n",
    "                new_labels.append(labels[j])\n",
    "        num_none_labels += len(sentences) - len(new_sentences)\n",
    "       \n",
    "        # assert equal lengths\n",
    "        assert len(new_sentences) == len(new_labels)\n",
    "        # add entry in the data dict\n",
    "        data[f'file_{i+1}'] = {'sentences':new_sentences, 'labels':new_labels, 'file_name':file}\n",
    "    print(f'total of {num_none_labels} elements got deleted as of None labels')\n",
    "    return data\n",
    "\n",
    "def load_data(path) -> dict:\n",
    "    json_file = load_json_file(path)\n",
    "    data = construct_data_labels(json_file)\n",
    "    return data\n",
    "\n",
    "def docs_to_df(data: dict):\n",
    "    dfs = []\n",
    "    for doc in data.keys():\n",
    "        dfs.append(pd.DataFrame(data[doc]))\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61f11f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of 53 elements got deleted as of None labels\n",
      "total of 2 elements got deleted as of None labels\n",
      "total of 1 elements got deleted as of None labels\n",
      "total of 244 elements got deleted as of None labels\n",
      "total of 31 elements got deleted as of None labels\n",
      "total of 23 elements got deleted as of None labels\n"
     ]
    }
   ],
   "source": [
    "train_cl = load_data(path_cl_train)\n",
    "dev_cl = load_data(path_cl_dev)\n",
    "test_cl = load_data(path_cl_test)\n",
    "\n",
    "train_it = load_data(path_it_train)\n",
    "dev_it = load_data(path_it_dev)\n",
    "test_it = load_data(path_it_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71c2d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cl_df = docs_to_df(train_cl)\n",
    "dev_cl_df = docs_to_df(dev_cl)\n",
    "test_cl_df = docs_to_df(test_cl)\n",
    "\n",
    "train_it_df = docs_to_df(train_it)\n",
    "dev_it_df = docs_to_df(dev_it)\n",
    "test_it_df = docs_to_df(test_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d72ba194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The CL data has: 10540 Train, 1394 dev,1338 Test Sentences.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'The CL data has: {train_cl_df.shape[0]} Train, {dev_cl_df.shape[0]} dev,{test_cl_df.shape[0]} Test Sentences.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce815ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The CL data has: 6008 Train, 715 dev,835 Test Sentences.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'The CL data has: {train_it_df.shape[0]} Train, {dev_it_df.shape[0]} dev,{test_it_df.shape[0]} Test Sentences.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6b24e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cl_df.to_csv('train_cl.csv', index = False)\n",
    "dev_cl_df.to_csv('dev_cl.csv', index = False)\n",
    "test_cl_df.to_csv('test_cl.csv', index = False)\n",
    "\n",
    "train_it_df.to_csv('train_it.csv', index = False)\n",
    "dev_it_df.to_csv('dev_it.csv', index = False)\n",
    "test_it_df.to_csv('test_it.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19a907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lnlp",
   "language": "python",
   "name": "lnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
