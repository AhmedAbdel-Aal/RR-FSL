{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d83ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all required libraries\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3fafd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## installing Transformers\n",
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9b121e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Loading the model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "## Setting model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9417f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "## path for the training and testing files\n",
    "main_input_path = '/Users/ahmed/Desktop/SS23/practical-legalNLP/data'\n",
    "\n",
    "path_cl_train = Path(main_input_path, 'CL','CL_train.json')\n",
    "path_cl_dev = Path(main_input_path, 'CL','CL_dev.json')\n",
    "path_cl_test = Path(main_input_path, 'CL','CL_test.json')\n",
    "\n",
    "path_it_train = Path(main_input_path, 'IT','IT_train.json')\n",
    "path_it_dev = Path(main_input_path, 'IT','IT_dev.json')\n",
    "path_it_test = Path(main_input_path, 'IT','IT_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfabbb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_output_path = './bert_sentence_independent_embeddings'\n",
    "\n",
    "output_cl_train = Path(main_output_path,'CL_train')\n",
    "output_cl_dev = Path(main_output_path,'CL_dev.pkl')\n",
    "output_cl_test = Path(main_output_path,'CL_test.pkl')\n",
    "\n",
    "output_it_train = Path(main_output_path,'IT_train.pkl')\n",
    "output_it_dev = Path(main_output_path,'IT_dev.pkl')\n",
    "output_it_test = Path(main_output_path,'IT_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a620b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(path) -> dict:\n",
    "    with open(path,'r') as f:\n",
    "        d = json.load(f)\n",
    "    return d\n",
    "\n",
    "def save_pickle(path, d):\n",
    "    # Check if d is a dictionary\n",
    "    assert isinstance(d, dict), \"Input must be a dictionary\"\n",
    "\n",
    "    # Check if the path ends with '.pkl' and add it if needed\n",
    "    path  = path.with_suffix(\".pkl\")\n",
    "    # Save the dictionary using pickle\n",
    "    print(f'Saving data ..... in {path}')\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c64802fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_bert_embeddings(tokenizer, model, sentence):\n",
    "    tokenized_text = tokenizer.encode_plus(sentence, padding='max_length', truncation=True, return_tensors='pt', max_length=512)\n",
    "    indexed_tokens = tokenized_text['input_ids']\n",
    "    with torch.no_grad():\n",
    "        outputs = model(indexed_tokens)\n",
    "    sentence_embedding = outputs[0].squeeze()[0].flatten().tolist()\n",
    "    return sentence_embedding\n",
    "\n",
    "def get_doc_bert_embeddings(tokenizer, model, doc):\n",
    "        sentences = doc['sentences']\n",
    "        labels = doc['complete']\n",
    "                \n",
    "        if isinstance(sentences, str):\n",
    "            sentences = sentences[2:-2].split('\\', \\'')\n",
    "        \n",
    "        # remove sentences with None labels\n",
    "        new_sentences = []\n",
    "        new_labels = []\n",
    "        for j,l in enumerate(labels):\n",
    "            if (l == 'None'):\n",
    "                continue\n",
    "            else:\n",
    "                new_sentences.append(sentences[j])\n",
    "                new_labels.append(labels[j])\n",
    "        \n",
    "        embeddings = []\n",
    "        for idx in range(len(new_sentences)):\n",
    "            sentence_embedding = get_sentence_bert_embeddings(tokenizer, model, new_sentences[idx])\n",
    "            embeddings.append(sentence_embedding)\n",
    "        return {'embeddings':embeddings, 'labels':new_labels}\n",
    "\n",
    "            \n",
    "def prepare_data(data_input_path, data_output_path, tokenizer, model):\n",
    "        data_dict = load_json_file(data_input_path)\n",
    "        data_output_dict = {}\n",
    "        for file in tqdm(data_dict.keys()):\n",
    "            doc = data_dict[file]\n",
    "            doc_embedded = get_doc_bert_embeddings(tokenizer, model, doc)\n",
    "            data_output_dict[file] = doc_embedded\n",
    "        save_pickle(data_output_path, data_output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353594e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▊                                   | 8/40 [02:38<12:13, 22.91s/it]"
     ]
    }
   ],
   "source": [
    "prepare_data(path_cl_train, output_cl_train, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9cfebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data(path_cl_dev, output_cl_dev, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f545cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████         | 4/5 [01:38<00:25, 25.27s/it]"
     ]
    }
   ],
   "source": [
    "prepare_data(path_cl_test, output_cl_test, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd048dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data(path_it_train, output_it_train, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data(path_it_dev, output_it_dev, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data(path_it_test, output_it_test, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9034608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lnlp",
   "language": "python",
   "name": "lnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
